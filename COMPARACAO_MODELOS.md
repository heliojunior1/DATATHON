# Compara√ß√£o de Modelos ‚Äî Datathon Passos M√°gicos

> **Data:** 16/02/2026 &nbsp;|&nbsp; **Dataset:** 860 alunos (688 treino / 172 teste) &nbsp;|&nbsp; **Features:** 35 &nbsp;|&nbsp; **Target:** Risco de evas√£o (69.9% positivo)

---

## 1. M√©tricas no Test Set

| Modelo | Accuracy | F1 Score | Precision | Recall | AUC-ROC |
|--------|:--------:|:--------:|:---------:|:------:|:-------:|
| **CatBoost** ü•á | **1.0000** | **1.0000** | **1.0000** | **1.0000** | **1.0000** |
| **LightGBM** ü•à | 0.9942 | 0.9959 | 0.9917 | **1.0000** | **1.0000** |
| **TabPFN** ü•â | 0.9826 | 0.9876 | 0.9835 | 0.9917 | 0.9997 |
| **XGBoost** | 0.9593 | 0.9702 | 0.9913 | 0.9500 | 0.9966 |

---

## 2. Cross-Validation (5-Fold Estratificado)

| Modelo | CV F1 (m√©dia ¬± std) | CV Accuracy | CV Precision | CV Recall | CV AUC-ROC |
|--------|:-------------------:|:-----------:|:------------:|:---------:|:----------:|
| **TabPFN** ü•á | **0.9958 ¬± 0.0027** | **0.9942 ¬± 0.0037** | **0.9983 ¬± 0.0033** | 0.9933 ¬± 0.0062 | **0.9997 ¬± 0.0004** |
| **CatBoost** ü•à | 0.9918 ¬± 0.0093 | 0.9884 ¬± 0.0133 | 0.9839 ¬± 0.0181 | **1.0000 ¬± 0.0000** | 0.9994 ¬± 0.0012 |
| **LightGBM** ü•â | 0.9910 ¬± 0.0070 | 0.9872 ¬± 0.0100 | 0.9838 ¬± 0.0143 | 0.9983 ¬± 0.0033 | 0.9988 ¬± 0.0016 |
| **XGBoost** | 0.9742 ¬± 0.0060 | 0.9640 ¬± 0.0085 | 0.9770 ¬± 0.0158 | 0.9717 ¬± 0.0135 | 0.9926 ¬± 0.0061 |

> [!IMPORTANT]
> No **Cross-Validation**, o TabPFN lidera com o maior F1 e o menor desvio-padr√£o (0.0027), indicando a melhor **consist√™ncia** entre todos os modelos. CatBoost lidera no test set, mas TabPFN generaliza melhor.

---

## 3. Matriz de Confus√£o (Test Set)

| Modelo | TN | FP | FN | TP | Erros |
|--------|:--:|:--:|:--:|:--:|:-----:|
| CatBoost | 52 | 0 | 0 | 120 | 0 |
| LightGBM | 51 | 1 | 0 | 120 | 1 |
| TabPFN | 51 | 1 | 1 | 119 | 2 |
| XGBoost | 51 | 1 | 6 | 114 | 7 |

> [!WARNING]
> O XGBoost teve **6 falsos negativos** (alunos em risco classificados como sem risco). Para detec√ß√£o de risco de evas√£o, CatBoost e LightGBM (100% recall) s√£o prefer√≠veis.

---

## 4. Top 10 Features Mais Importantes

### Por Modelo (Top 5)

| # | XGBoost | CatBoost | LightGBM | TabPFN |
|---|---------|----------|----------|--------|
| 1 | N¬∫ Av | **Idade 22** | **Idade 22** | **Idade 22** |
| 2 | Idade 22 | **Fase_encoded** | **Fase_encoded** | INDE 22 |
| 3 | Fase_encoded | N¬∫ Av | Cf | Cf |
| 4 | Indicado_flag | Cf | IPV | IEG |
| 5 | Cf | INDE 22 | INDE 22 | IPV |

> [!NOTE]
> **Consenso entre modelos:** `Idade 22` √© a feature mais importante em 3 dos 4 modelos. `Cf`, `INDE 22` e `IPV` tamb√©m aparecem consistentemente no top 5. As escalas de import√¢ncia diferem por modelo (XGBoost=gain fraction, CatBoost=prediction value change, LightGBM=split count, TabPFN=permutation importance).

---

## 5. An√°lise e Recomenda√ß√µes

### Ranking Final

| Pos | Modelo | Test F1 | CV F1 | Pontos Fortes | Pontos Fracos |
|:---:|--------|:-------:|:-----:|---------------|---------------|
| ü•á | **CatBoost** | 1.0000 | 0.9918 | Melhor test set, 100% recall, robusto a NaN | Poss√≠vel leve overfitting |
| ü•à | **TabPFN** | 0.9876 | **0.9958** | **Melhor CV**, mais consistente, sem tuning | Lento, n√£o suporta NaN, limite de features |
| ü•â | **LightGBM** | 0.9959 | 0.9910 | R√°pido, 100% recall, robusto a NaN | 1 FP |
| 4 | **XGBoost** | 0.9702 | 0.9742 | Estabelecido, boa calibra√ß√£o | 6 FN, recall mais baixo |

### Recomenda√ß√£o

Para **detec√ß√£o de risco de evas√£o escolar** (custo alto de falso negativo):

- **Produ√ß√£o:** **CatBoost** como modelo principal (100% recall + melhor precis√£o no test set)
- **Valida√ß√£o:** **TabPFN** como refer√™ncia de generaliza√ß√£o (melhor CV F1, menor vari√¢ncia)
- **Backup:** **LightGBM** como alternativa r√°pida com 100% recall

---

## 6. Modelos na API

```json
POST /train
{
  "model_type": "catboost"  // ou "xgboost", "lightgbm", "tabpfn"
}
```

| Tipo | Status | Model ID |
|------|--------|----------|
| xgboost | ‚úÖ Operacional | `xgb_20260216_104712` |
| catboost | ‚úÖ Operacional | `cat_20260216_104720` |
| lightgbm | ‚úÖ Operacional | `lgb_20260216_104729` |
| tabpfn | ‚úÖ Operacional | `tpfn_20260216_105151` |

> [!NOTE]
> TabPFN v1 (0.1.11) requer o patch `python scripts/patch_tabpfn.py` ap√≥s instala√ß√£o para compatibilidade com PyTorch ‚â• 2.0.
