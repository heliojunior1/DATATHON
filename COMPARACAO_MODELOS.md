# Compara√ß√£o de Modelos ‚Äî Datathon Passos M√°gicos

> **Data:** 16/02/2026 &nbsp;|&nbsp; **Dataset:** 860 alunos (688 treino / 172 teste) &nbsp;|&nbsp; **Features:** 35 &nbsp;|&nbsp; **Target:** Risco de evas√£o (69.9% positivo)

---

## 1. M√©tricas no Test Set

| Modelo | Accuracy | F1 Score | Precision | Recall | AUC-ROC |
|--------|:--------:|:--------:|:---------:|:------:|:-------:|
| **CatBoost** ü•á | **1.0000** | **1.0000** | **1.0000** | **1.0000** | **1.0000** |
| **LightGBM** ü•à | 0.9942 | 0.9959 | 0.9917 | **1.0000** | **1.0000** |
| **XGBoost** ü•â | 0.9593 | 0.9702 | 0.9913 | 0.9500 | 0.9966 |
| TabPFN | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |

> [!NOTE]
> TabPFN n√£o p√¥de ser avaliado nesta compara√ß√£o pois o modelo pr√©-treinado requer autentica√ß√£o no HuggingFace (modelo *gated*). Veja instru√ß√µes em [docs.priorlabs.ai](https://docs.priorlabs.ai/how-to-access-gated-models).

---

## 2. Cross-Validation (5-Fold Estratificado)

| Modelo | CV F1 (m√©dia ¬± std) | CV Accuracy | CV Precision | CV Recall | CV AUC-ROC |
|--------|:-------------------:|:-----------:|:------------:|:---------:|:----------:|
| **CatBoost** ü•á | **0.9918 ¬± 0.0093** | 0.9884 ¬± 0.0133 | 0.9839 ¬± 0.0181 | **1.0000 ¬± 0.0000** | **0.9994 ¬± 0.0012** |
| **LightGBM** ü•à | 0.9910 ¬± 0.0070 | 0.9872 ¬± 0.0100 | 0.9838 ¬± 0.0143 | 0.9983 ¬± 0.0033 | 0.9988 ¬± 0.0016 |
| **XGBoost** ü•â | 0.9742 ¬± 0.0060 | 0.9640 ¬± 0.0085 | 0.9770 ¬± 0.0158 | 0.9717 ¬± 0.0135 | 0.9926 ¬± 0.0061 |

> [!IMPORTANT]
> Os resultados de **Cross-Validation confirmam o ranking** do test set. CatBoost e LightGBM s√£o muito pr√≥ximos (diferen√ßa de 0.08% no F1), enquanto XGBoost fica ~1.7% abaixo.

---

## 3. Matriz de Confus√£o (Test Set)

```
                 CatBoost          LightGBM          XGBoost
               Pred 0  Pred 1    Pred 0  Pred 1    Pred 0  Pred 1
Real 0 (52)      52      0         51      1         51      1
Real 1 (120)      0    120          0    120          6    114
```

| Modelo | TN | FP | FN | TP |
|--------|:--:|:--:|:--:|:--:|
| CatBoost | 52 | 0 | 0 | 120 |
| LightGBM | 51 | 1 | 0 | 120 |
| XGBoost | 51 | 1 | 6 | 114 |

> [!WARNING]
> O XGBoost teve **6 falsos negativos** (alunos em risco classificados como sem risco). Para um sistema de detec√ß√£o de risco de evas√£o, o Recall de 100% do CatBoost e LightGBM √© prefer√≠vel ‚Äî nenhum aluno em risco deixa de ser identificado.

---

## 4. Top 10 Features Mais Importantes

### CatBoost
| # | Feature | Import√¢ncia |
|---|---------|:-----------:|
| 1 | Idade 22 | 49.51 |
| 2 | Fase_encoded | 29.75 |
| 3 | N¬∫ Av | 5.19 |
| 4 | Cf | 5.15 |
| 5 | INDE 22 | 1.67 |
| 6 | IPV | 1.01 |
| 7 | Portug | 0.84 |
| 8 | IDA | 0.80 |
| 9 | Rec_av2_encoded | 0.72 |
| 10 | Ratio_IDA_IEG | 0.69 |

### LightGBM
| # | Feature | Import√¢ncia |
|---|---------|:-----------:|
| 1 | Idade 22 | 379 |
| 2 | Fase_encoded | 252 |
| 3 | Cf | 127 |
| 4 | IPV | 103 |
| 5 | INDE 22 | 91 |
| 6 | Ratio_IDA_IEG | 88 |
| 7 | Variancia_indicadores | 74 |
| 8 | IDA | 64 |
| 9 | Portug | 60 |
| 10 | Matem | 59 |

### XGBoost
| # | Feature | Import√¢ncia |
|---|---------|:-----------:|
| 1 | N¬∫ Av | 0.1113 |
| 2 | Idade 22 | 0.0754 |
| 3 | Fase_encoded | 0.0751 |
| 4 | Indicado_flag | 0.0707 |
| 5 | Cf | 0.0673 |
| 6 | Rec_av2_encoded | 0.0601 |
| 7 | Tem_nota_ingles | 0.0525 |
| 8 | Escola_encoded | 0.0497 |
| 9 | INDE 22 | 0.0458 |
| 10 | Variancia_indicadores | 0.0434 |

> [!NOTE]
> As escalas de import√¢ncia s√£o diferentes entre modelos (CatBoost usa *prediction value change*, LightGBM usa *split count*, XGBoost usa *gain fraction*), mas as **features mais relevantes s√£o consistentes**:
> - **Idade 22** e **Fase_encoded** dominam em todos os modelos
> - **Cf**, **INDE 22** e **IPV** aparecem no top 6 de todos
> - **N¬∫ Av** √© mais valorizada pelo XGBoost do que pelos outros

---

## 5. An√°lise e Recomenda√ß√µes

### Ranking Final

| Posi√ß√£o | Modelo | Pontos Fortes | Pontos Fracos |
|:-------:|--------|---------------|---------------|
| ü•á | **CatBoost** | Melhor desempenho geral, 100% recall, robusto a NaN, codifica√ß√£o categ√≥rica nativa | Pode indicar leve overfitting (100% test set), mais lento que LightGBM |
| ü•à | **LightGBM** | Muito pr√≥ximo do CatBoost, mais r√°pido, 100% recall | 1 falso positivo |
| ü•â | **XGBoost** | Robusto e bem estabelecido, boa calibra√ß√£o | 6 falsos negativos, recall menor |
| ‚Äî | **TabPFN** | Ideal para datasets pequenos, sem tuning necess√°rio | Requer autentica√ß√£o HuggingFace, depend√™ncia do PyTorch |

### Recomenda√ß√£o

Para o caso de uso de **detec√ß√£o de risco de evas√£o escolar**, onde o custo de um falso negativo (n√£o identificar um aluno em risco) √© alto:

- **Produ√ß√£o:** Usar **CatBoost** como modelo principal (melhor recall + precis√£o)
- **Backup:** **LightGBM** como alternativa r√°pida com desempenho quase id√™ntico
- **Monitorar:** Ficar atento a overfitting do CatBoost conforme novos dados entram ‚Äî o CV (F1=0.9918) confirma boa generaliza√ß√£o

---

## 6. Modelos Dispon√≠veis na API

Todos os modelos est√£o dispon√≠veis para treinamento via API:

```json
POST /train
{
  "model_type": "catboost",  // ou "xgboost", "lightgbm", "tabpfn"
  "optimize": false
}
```

| Tipo | Status | Model ID |
|------|--------|----------|
| xgboost | ‚úÖ Operacional | `xgb_20260216_101754` |
| catboost | ‚úÖ Operacional | `cat_20260216_101759` |
| lightgbm | ‚úÖ Operacional | `lgb_20260216_101808` |
| tabpfn | ‚ö†Ô∏è Requer HF Auth | ‚Äî |
