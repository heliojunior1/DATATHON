# ğŸ¯ Datathon Passos MÃ¡gicos â€” PrevisÃ£o de Risco de Defasagem Escolar

API de Machine Learning para estimar o risco de **defasagem escolar** dos estudantes da AssociaÃ§Ã£o Passos MÃ¡gicos, construÃ­da com **XGBoost** e **FastAPI**.

---

## ğŸ“‹ VisÃ£o Geral

### Problema de NegÃ³cio
A AssociaÃ§Ã£o Passos MÃ¡gicos transforma a vida de crianÃ§as e jovens em vulnerabilidade social por meio da educaÃ§Ã£o. Este projeto prevÃª quais alunos estÃ£o **em risco de defasagem escolar**, permitindo intervenÃ§Ãµes educacionais preventivas.

### SoluÃ§Ã£o Proposta
Pipeline completa de Machine Learning usando **XGBoost** como classificador binÃ¡rio:
- **Em Risco** (Defasagem â‰¤ -2): aluno atrasado 2+ fases
- **Sem Risco** (Defasagem â‰¥ -1): aluno no nÃ­vel adequado ou levemente atrasado

### Resultados do Modelo

#### MÃ©tricas (Conjunto de Teste)

| MÃ©trica | Valor |
|---------|-------|
| **Accuracy** | 95.93% |
| **Precision** | 99.13% |
| **Recall** | 95.00% |
| **F1-Score** | 97.02% |
| **AUC-ROC** | 99.66% |

#### Cross-Validation Independente (5-Fold)

| MÃ©trica | MÃ©dia Â± Std |
|---------|-------------|
| **Accuracy** | 96.40% Â± 0.85% |
| **Precision** | 97.70% Â± 1.58% |
| **Recall** | 97.17% Â± 1.35% |
| **F1-Score** | 97.42% Â± 0.60% |
| **AUC-ROC** | 99.26% Â± 0.61% |

> O desvio padrÃ£o baixo (< 1.6%) em todas as mÃ©tricas confirma que o modelo **generaliza bem** e nÃ£o apresenta overfitting.

### Stack TecnolÃ³gica
- **Linguagem**: Python 3.11
- **ML**: scikit-learn, XGBoost, pandas, numpy, matplotlib
- **Feature Store**: Feast + SQLite (Online) + Parquet (Offline)
- **API**: FastAPI + Uvicorn
- **SerializaÃ§Ã£o**: joblib
- **Testes**: pytest (126 testes)
- **Empacotamento**: Docker
- **Monitoramento**: drift detection (PSI, KS-test)

---

## ğŸ›ï¸ Arquitetura do Feature Store

A aplicaÃ§Ã£o agora utiliza o **Feast** como Feature Store local para centralizar e garantir a consistÃªncia das features entre treinamento e inferÃªncia.

```mermaid
graph LR
    A[Dataset PEDE<br>Excel] --> B[Preprocessing]
    B --> C[Feature Engineering]
    C --> D[Parquet Files<br>Offline Store]
    D --> E["feast apply<br>(Registry)"]
    E --> F["feast materialize<br>(SQLite Online Store)"]

    D -.->|Batch Df| G[Training Pipeline<br>Historical Features]
    F -.->|Low Latency| H[Prediction API<br>Online Features]
```

---

## ğŸ“ Estrutura do Projeto

```
datathon/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py          # Endpoints FastAPI
â”‚   â”‚   â””â”€â”€ schemas.py         # Modelos Pydantic
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py          # ConfiguraÃ§Ãµes centrais
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # PrÃ©-processamento
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # Engenharia de features
â”‚   â”‚   â”œâ”€â”€ train.py           # Pipeline de treinamento
â”‚   â”‚   â”œâ”€â”€ evaluate.py        # MÃ©tricas e AvaliaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ predict.py         # PrediÃ§Ã£o
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â””â”€â”€ drift.py           # DetecÃ§Ã£o de data drift
â”‚   â””â”€â”€ main.py                # Entrada da aplicaÃ§Ã£o
â”œâ”€â”€ feature_store/             # Feast Feature Store
â”‚   â”œâ”€â”€ data/                  # SQLite DBs e .parquet
â”‚   â”œâ”€â”€ data_sources.py        # Fontes de dados Parquet
â”‚   â”œâ”€â”€ entities.py            # Entidade Aluno
â”‚   â”œâ”€â”€ feature_store_manager.py # Interface do Feast
â”‚   â”œâ”€â”€ feature_store.yaml     # Config do Feast
â”‚   â””â”€â”€ features.py            # 8 Feature Views
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ materialize_features.py # Script de materializaÃ§Ã£o
â”œâ”€â”€ data/                       # Dataset PEDE 2024
â”œâ”€â”€ models/                     # Modelos serializados
â”œâ”€â”€ tests/                      # Testes unitÃ¡rios (126 testes)
â”œâ”€â”€ train_pipeline.py           # Script CLI de treinamento
â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ InstruÃ§Ãµes de Deploy

### PrÃ©-requisitos
- Python 3.11+
- pip

### 1. Configurar Ambiente Virtual (Recomendado)

```bash
# Criar venv
python -m venv venv

# Ativar venv (Windows)
.\venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Inicializar o Feature Store

Antes de treinar ou usar a API, popule o Feature Store:

```bash
python scripts/materialize_features.py
```
Isso irÃ¡ criar os arquivos Parquet (offline store) e popular o SQLite (online store).

### 3. Treinar o Modelo

```bash
# Treinamento usando as features salvas no Feature Store
python train_pipeline.py --use-feature-store

# Treinamento completo (com otimizaÃ§Ã£o e Feature Store)
python train_pipeline.py --use-feature-store

# Sem a feature IAN (jÃ¡ Ã© o padrÃ£o)
python train_pipeline.py --no-ian
```

### 4. Iniciar a API

```bash
python -m uvicorn app.main:app --host 127.0.0.1 --port 8000
```

A documentaÃ§Ã£o interativa estarÃ¡ em: http://localhost:8000/docs


### 4. Analise dos dados
TIER 1 â€” Usar com confianÃ§a (< 30% nulos, alta relevÃ¢ncia)
Feature	Tipo	Escala	Nulos	NormalizaÃ§Ã£o	ObservaÃ§Ã£o
INDE	NumÃ©rico	0â€“10	~20%	StandardScaler	Ãndice composto principal
IAA	NumÃ©rico	0â€“10	~20%	StandardScaler	Auto-avaliaÃ§Ã£o do aluno
IEG	NumÃ©rico	0â€“10	~20%	StandardScaler	Engajamento (liÃ§Ãµes de casa)
IPS	NumÃ©rico	0â€“10	~20%	StandardScaler	Psicossocial
IDA	NumÃ©rico	0â€“10	~20%	StandardScaler	Desempenho acadÃªmico
IPP	NumÃ©rico	0â€“10	~20%	StandardScaler	PsicopedagÃ³gico
IPV	NumÃ©rico	0â€“10	~20%	StandardScaler	AvaliaÃ§Ã£o de "ponto de virada"
PEDRA	Ordinal	4 classes	~20%	OrdinalEncoder (1-4)	Hierarquia natural
Idade	NumÃ©rico	~8â€“20	~25%	StandardScaler	DemogrÃ¡fica
Ano ingresso	NumÃ©rico	2016â€“2022	~25%	Derivar Anos_na_PM	Tempo no programa
GÃªnero	BinÃ¡rio	2 classes	~25%	LabelEncoder (0/1)	DemogrÃ¡fica
TIER 2 â€” Usar com cautela (30â€“60% nulos ou risco de leakage)
Feature	Tipo	Nulos	Problema	RecomendaÃ§Ã£o
IAN	NumÃ©rico (discreto: 0, 5, 10)	~25%	DATA LEAKAGE â€” Ã© praticamente sinÃ´nimo de defasagem. Domina com 58.4% de importÃ¢ncia	REMOVER do modelo principal. IAN mede "adequaÃ§Ã£o ao nÃ­vel", que Ã© o prÃ³prio target
DEFASAGEM	NumÃ©rico	~30%	Ã‰ o target, nÃ£o feature	Usar sÃ³ para criar y
Ponto de Virada	BinÃ¡rio	~25%	Pode ser consequÃªncia, nÃ£o causa	Usar com monitoramento
Rec Psicologia	Ordinal (5 nÃ­veis)	~40%	Muitos nulos	Imputar como "NÃ£o avaliado" (0)
Rec Avaliador 1/2	Ordinal (5 nÃ­veis)	~40%	PossÃ­vel leakage â€” avaliadores podem ver defasagem	Testar modelo com e sem
TIER 3 â€” Evitar (> 60% nulos ou irrelevantes)
Feature	Nulos	Por que evitar
NOTA_PORT / NOTA_MAT / NOTA_ING	~70-80%	Quase inÃºtil â€” tÃ£o poucos dados que a imputaÃ§Ã£o por mediana distorce a realidade
Cg, Cf, Ct	~25%	Significado nÃ£o documentado no dicionÃ¡rio. Rankings internos? PossÃ­vel leakage
DESTAQUE_IEG/IDA/IPV	Texto livre	NÃ£o processÃ¡vel sem NLP
REC_EQUIPE_*	~50%	Muitas categorias, muitos nulos
TURMA	~30%	Identificador, sem valor preditivo
NOME	0%	Identificador pessoal
INDE_CONCEITO	~20%	Redundante â€” Ã© apenas a faixa do INDE
NÂº Av	~25%	Se reflete nÃºmero de avaliaÃ§Ãµes do mesmo perÃ­odo, pode ser leaker

### 5. Deploy com Docker

```bash
# Build
docker build -t datathon-passos .

# Run
docker run -p 8000:8000 datathon-passos

# Ou com docker-compose
docker-compose up -d
```

---

## ğŸ”Œ Exemplos de Chamadas Ã  API

### Health Check

```bash
curl http://localhost:8000/health
```

**Resposta:**
```json
{
  "status": "ok",
  "model_loaded": true,
  "model_name": "xgboost_defasagem",
  "model_version": "1.0.0"
}
```

### PrediÃ§Ã£o Individual

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "IAA": 7.5,
    "IEG": 8.0,
    "IPS": 6.5,
    "IDA": 7.0,
    "IPV": 5.5,
    "IAN": 5.0,
    "INDE 22": 7.2,
    "Matem": 7.5,
    "Portug": 6.8,
    "InglÃªs": 7.0,
    "Idade 22": 14,
    "GÃªnero": "Menina",
    "InstituiÃ§Ã£o de ensino": "Escola PÃºblica",
    "Ano ingresso": 2018,
    "Pedra 22": "Ametista",
    "Rec Psicologia": "Sem limitaÃ§Ãµes",
    "Atingiu PV": "NÃ£o",
    "Indicado": "NÃ£o",
    "Cg": 300,
    "Cf": 50,
    "Ct": 5,
    "NÂº Av": 3
  }'
```

**Resposta:**
```json
{
  "prediction": 0,
  "probability": 0.1234,
  "risk_level": "Muito Baixo",
  "label": "Sem Risco",
  "top_factors": [
    {"feature": "NÂº Av", "importance": 0.1113},
    {"feature": "Idade 22", "importance": 0.0754}
  ]
}
```

### PrediÃ§Ã£o em Lote

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{"students": [<aluno1>, <aluno2>, ...]}'
```

### InformaÃ§Ãµes do Modelo

```bash
curl http://localhost:8000/model-info
```

### Learning Curves (PNG)

```bash
curl http://localhost:8000/learning-curve --output learning_curves.png
```

### Monitoramento de Drift

```bash
curl http://localhost:8000/monitoring/drift
curl http://localhost:8000/monitoring/stats
```

---

## ğŸ”¬ Pipeline de Machine Learning

### 1. PrÃ©-processamento
- Carregamento do dataset PEDE 2024 (860 alunos Ã— 42 colunas)
- CriaÃ§Ã£o da variÃ¡vel target binÃ¡ria (Defas â‰¤ -2 â†’ em risco)
- CodificaÃ§Ã£o ordinal de categÃ³ricas (Pedras, GÃªnero, Escola, Rec. Psicologia)
- Tratamento de nulos (mediana para Math/Port, NaN nativo para XGBoost)

### 2. Engenharia de Features
- **35 features** selecionadas (sem IAN â€” removido por data leakage)
- EvoluÃ§Ã£o temporal das Pedras (2020â†’2022, 2021â†’2022)
- Anos na Passos MÃ¡gicos
- Flags de destaque (IEG, IDA, IPV)
- Features derivadas: `Variancia_indicadores`, `Ratio_IDA_IEG`

### 3. Treinamento com RegularizaÃ§Ã£o

O XGBoost Ã© treinado com **regularizaÃ§Ã£o** para evitar overfitting (sem regularizaÃ§Ã£o, o treino atingia 100%):

| ParÃ¢metro | Valor | Efeito |
|-----------|-------|--------|
| `max_depth` | 4 | Limita profundidade das Ã¡rvores (padrÃ£o: 6) |
| `min_child_weight` | 5 | MÃ­nimo de amostras por folha |
| `subsample` | 0.8 | Amostragem de 80% dos dados por Ã¡rvore |
| `colsample_bytree` | 0.8 | Amostragem de 80% das features por Ã¡rvore |
| `reg_alpha` | 0.1 | RegularizaÃ§Ã£o L1 (sparsity) |
| `reg_lambda` | 1.0 | RegularizaÃ§Ã£o L2 (weight decay) |
| `learning_rate` | 0.1 | Taxa de aprendizado conservadora |
| `n_estimators` | 200 | Mais Ã¡rvores compensam o learning_rate menor |

Essa configuraÃ§Ã£o reduziu o score de treino de **1.000 para ~0.99** e manteve o score de validaÃ§Ã£o estÃ¡vel, eliminando o overfitting.

### 4. ValidaÃ§Ã£o

- **Cross-Validation Independente (5-Fold)**: avalia generalizaÃ§Ã£o do modelo no dataset completo, reportando mÃ©dia Â± desvio padrÃ£o por mÃ©trica
- **Learning Curves**: grÃ¡fico de treino vs validaÃ§Ã£o em funÃ§Ã£o do tamanho do dataset para diagnÃ³stico visual de overfitting/underfitting
- MÃ©trica primÃ¡ria: **F1-Score** (equilÃ­brio entre precisÃ£o e recall)
- PriorizaÃ§Ã£o do **Recall** (evitar falsos negativos â€” nÃ£o perder alunos em risco)

### 5. Top Features

| # | Feature | ImportÃ¢ncia |
|---|---------|------------|
| 1 | NÂº AvaliaÃ§Ãµes | 11.13% |
| 2 | Idade 22 | 7.54% |
| 3 | Fase (encoded) | 7.51% |
| 4 | Indicado (flag) | 7.07% |
| 5 | Cf | 6.73% |

> A importÃ¢ncia estÃ¡ bem distribuÃ­da entre as features (max. 11%), indicando que o modelo nÃ£o depende de uma Ãºnica variÃ¡vel.

---

## ğŸ§ª Testes

```bash
# Executar todos os testes
pytest tests/ -v

# Com cobertura
pytest tests/ --cov=app --cov-report=term-missing

# Verificar cobertura mÃ­nima de 80%
pytest tests/ --cov=app --cov-fail-under=80
```

**Resultado atual**: 105 testes passando.

---

## ğŸ“Š Monitoramento

A API inclui monitoramento contÃ­nuo de **data drift**:

- **PSI (Population Stability Index)**: detecta mudanÃ§as na distribuiÃ§Ã£o das features
- **KS-test**: teste estatÃ­stico contra distribuiÃ§Ã£o de referÃªncia
- **Logs de prediÃ§Ã£o**: todas as prediÃ§Ãµes sÃ£o registradas para anÃ¡lise

Endpoints:
- `GET /monitoring/drift` â€” Status de drift por feature
- `GET /monitoring/stats` â€” EstatÃ­sticas das prediÃ§Ãµes

---

## ğŸ“„ LicenÃ§a

Projeto desenvolvido para o Datathon PÃ“S TECH â€” Machine Learning Engineering.

