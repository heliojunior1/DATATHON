# üéØ Datathon Passos M√°gicos ‚Äî Previs√£o de Risco de Defasagem Escolar

API de Machine Learning para estimar o risco de **defasagem escolar** dos estudantes da Associa√ß√£o Passos M√°gicos, constru√≠da com **XGBoost** e **FastAPI**.

---

## üìã Vis√£o Geral

### Problema de Neg√≥cio
A Associa√ß√£o Passos M√°gicos transforma a vida de crian√ßas e jovens em vulnerabilidade social por meio da educa√ß√£o. Este projeto prev√™ quais alunos est√£o **em risco de defasagem escolar**, permitindo interven√ß√µes educacionais preventivas.

### Solu√ß√£o Proposta
Pipeline completa de Machine Learning usando **XGBoost** como classificador bin√°rio:
- **Em Risco** (Defasagem ‚â§ -2): aluno atrasado 2+ fases
- **Sem Risco** (Defasagem ‚â• -1): aluno no n√≠vel adequado ou levemente atrasado

### Resultados do Modelo

#### M√©tricas (Conjunto de Teste)

| M√©trica | Valor |
|---------|-------|
| **Accuracy** | 95.93% |
| **Precision** | 99.13% |
| **Recall** | 95.00% |
| **F1-Score** | 97.02% |
| **AUC-ROC** | 99.66% |

#### Cross-Validation Independente (5-Fold)

| M√©trica | M√©dia ¬± Std |
|---------|-------------|
| **Accuracy** | 96.40% ¬± 0.85% |
| **Precision** | 97.70% ¬± 1.58% |
| **Recall** | 97.17% ¬± 1.35% |
| **F1-Score** | 97.42% ¬± 0.60% |
| **AUC-ROC** | 99.26% ¬± 0.61% |

> O desvio padr√£o baixo (< 1.6%) em todas as m√©tricas confirma que o modelo **generaliza bem** e n√£o apresenta overfitting.

### Stack Tecnol√≥gica
- **Linguagem**: Python 3.11
- **ML**: scikit-learn, XGBoost, pandas, numpy, matplotlib
- **API**: FastAPI + Uvicorn
- **Serializa√ß√£o**: joblib
- **Testes**: pytest (105 testes)
- **Empacotamento**: Docker
- **Monitoramento**: drift detection (PSI, KS-test)

---

## üìÅ Estrutura do Projeto

```
datathon/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py          # Endpoints FastAPI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py         # Modelos Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py          # Configura√ß√µes centrais
‚îÇ   ‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py   # Pr√©-processamento de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py  # Engenharia de features
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py           # Pipeline de treinamento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py        # M√©tricas, CV e Learning Curves
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py         # L√≥gica de predi√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ drift.py           # Detec√ß√£o de data drift
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.py         # Utilit√°rios (logging)
‚îÇ   ‚îî‚îÄ‚îÄ main.py                # Entrada da aplica√ß√£o FastAPI
‚îú‚îÄ‚îÄ data/                       # Dataset PEDE 2024
‚îú‚îÄ‚îÄ models/                     # Modelos serializados + learning_curves.png
‚îú‚îÄ‚îÄ tests/                      # Testes unit√°rios (105 testes)
‚îú‚îÄ‚îÄ train_pipeline.py           # Script CLI de treinamento
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üöÄ Instru√ß√µes de Deploy

### Pr√©-requisitos
- Python 3.11+
- pip

### 1. Configurar Ambiente Virtual (Recomendado)

```bash
# Criar venv
python -m venv venv

# Ativar venv (Windows)
.\venv\Scripts\activate

# Instalar depend√™ncias
pip install -r requirements.txt
```

### 2. Treinar o Modelo

```bash
# Treinamento r√°pido (sem otimiza√ß√£o de hiperpar√¢metros)
python train_pipeline.py --no-optimize

# Treinamento completo (com RandomizedSearchCV)
python train_pipeline.py

# Sem a feature IAN (evitar data leakage ‚Äî j√° √© o padr√£o)
python train_pipeline.py --no-ian

# Pular CV e/ou learning curves para treino mais r√°pido
python train_pipeline.py --no-optimize --skip-cv --skip-learning-curves
```

### 3. Iniciar a API

```bash
python -m uvicorn app.main:app --host 127.0.0.1 --port 8000
```

A documenta√ß√£o interativa estar√° em: http://localhost:8000/docs


### 4. Analise dos dados
TIER 1 ‚Äî Usar com confian√ßa (< 30% nulos, alta relev√¢ncia)
Feature	Tipo	Escala	Nulos	Normaliza√ß√£o	Observa√ß√£o
INDE	Num√©rico	0‚Äì10	~20%	StandardScaler	√çndice composto principal
IAA	Num√©rico	0‚Äì10	~20%	StandardScaler	Auto-avalia√ß√£o do aluno
IEG	Num√©rico	0‚Äì10	~20%	StandardScaler	Engajamento (li√ß√µes de casa)
IPS	Num√©rico	0‚Äì10	~20%	StandardScaler	Psicossocial
IDA	Num√©rico	0‚Äì10	~20%	StandardScaler	Desempenho acad√™mico
IPP	Num√©rico	0‚Äì10	~20%	StandardScaler	Psicopedag√≥gico
IPV	Num√©rico	0‚Äì10	~20%	StandardScaler	Avalia√ß√£o de "ponto de virada"
PEDRA	Ordinal	4 classes	~20%	OrdinalEncoder (1-4)	Hierarquia natural
Idade	Num√©rico	~8‚Äì20	~25%	StandardScaler	Demogr√°fica
Ano ingresso	Num√©rico	2016‚Äì2022	~25%	Derivar Anos_na_PM	Tempo no programa
G√™nero	Bin√°rio	2 classes	~25%	LabelEncoder (0/1)	Demogr√°fica
TIER 2 ‚Äî Usar com cautela (30‚Äì60% nulos ou risco de leakage)
Feature	Tipo	Nulos	Problema	Recomenda√ß√£o
IAN	Num√©rico (discreto: 0, 5, 10)	~25%	DATA LEAKAGE ‚Äî √© praticamente sin√¥nimo de defasagem. Domina com 58.4% de import√¢ncia	REMOVER do modelo principal. IAN mede "adequa√ß√£o ao n√≠vel", que √© o pr√≥prio target
DEFASAGEM	Num√©rico	~30%	√â o target, n√£o feature	Usar s√≥ para criar y
Ponto de Virada	Bin√°rio	~25%	Pode ser consequ√™ncia, n√£o causa	Usar com monitoramento
Rec Psicologia	Ordinal (5 n√≠veis)	~40%	Muitos nulos	Imputar como "N√£o avaliado" (0)
Rec Avaliador 1/2	Ordinal (5 n√≠veis)	~40%	Poss√≠vel leakage ‚Äî avaliadores podem ver defasagem	Testar modelo com e sem
TIER 3 ‚Äî Evitar (> 60% nulos ou irrelevantes)
Feature	Nulos	Por que evitar
NOTA_PORT / NOTA_MAT / NOTA_ING	~70-80%	Quase in√∫til ‚Äî t√£o poucos dados que a imputa√ß√£o por mediana distorce a realidade
Cg, Cf, Ct	~25%	Significado n√£o documentado no dicion√°rio. Rankings internos? Poss√≠vel leakage
DESTAQUE_IEG/IDA/IPV	Texto livre	N√£o process√°vel sem NLP
REC_EQUIPE_*	~50%	Muitas categorias, muitos nulos
TURMA	~30%	Identificador, sem valor preditivo
NOME	0%	Identificador pessoal
INDE_CONCEITO	~20%	Redundante ‚Äî √© apenas a faixa do INDE
N¬∫ Av	~25%	Se reflete n√∫mero de avalia√ß√µes do mesmo per√≠odo, pode ser leaker

### 5. Deploy com Docker

```bash
# Build
docker build -t datathon-passos .

# Run
docker run -p 8000:8000 datathon-passos

# Ou com docker-compose
docker-compose up -d
```

---

## üîå Exemplos de Chamadas √† API

### Health Check

```bash
curl http://localhost:8000/health
```

**Resposta:**
```json
{
  "status": "ok",
  "model_loaded": true,
  "model_name": "xgboost_defasagem",
  "model_version": "1.0.0"
}
```

### Predi√ß√£o Individual

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "IAA": 7.5,
    "IEG": 8.0,
    "IPS": 6.5,
    "IDA": 7.0,
    "IPV": 5.5,
    "IAN": 5.0,
    "INDE 22": 7.2,
    "Matem": 7.5,
    "Portug": 6.8,
    "Ingl√™s": 7.0,
    "Idade 22": 14,
    "G√™nero": "Menina",
    "Institui√ß√£o de ensino": "Escola P√∫blica",
    "Ano ingresso": 2018,
    "Pedra 22": "Ametista",
    "Rec Psicologia": "Sem limita√ß√µes",
    "Atingiu PV": "N√£o",
    "Indicado": "N√£o",
    "Cg": 300,
    "Cf": 50,
    "Ct": 5,
    "N¬∫ Av": 3
  }'
```

**Resposta:**
```json
{
  "prediction": 0,
  "probability": 0.1234,
  "risk_level": "Muito Baixo",
  "label": "Sem Risco",
  "top_factors": [
    {"feature": "N¬∫ Av", "importance": 0.1113},
    {"feature": "Idade 22", "importance": 0.0754}
  ]
}
```

### Predi√ß√£o em Lote

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{"students": [<aluno1>, <aluno2>, ...]}'
```

### Informa√ß√µes do Modelo

```bash
curl http://localhost:8000/model-info
```

### Learning Curves (PNG)

```bash
curl http://localhost:8000/learning-curve --output learning_curves.png
```

### Monitoramento de Drift

```bash
curl http://localhost:8000/monitoring/drift
curl http://localhost:8000/monitoring/stats
```

---

## üî¨ Pipeline de Machine Learning

### 1. Pr√©-processamento
- Carregamento do dataset PEDE 2024 (860 alunos √ó 42 colunas)
- Cria√ß√£o da vari√°vel target bin√°ria (Defas ‚â§ -2 ‚Üí em risco)
- Codifica√ß√£o ordinal de categ√≥ricas (Pedras, G√™nero, Escola, Rec. Psicologia)
- Tratamento de nulos (mediana para Math/Port, NaN nativo para XGBoost)

### 2. Engenharia de Features
- **35 features** selecionadas (sem IAN ‚Äî removido por data leakage)
- Evolu√ß√£o temporal das Pedras (2020‚Üí2022, 2021‚Üí2022)
- Anos na Passos M√°gicos
- Flags de destaque (IEG, IDA, IPV)
- Features derivadas: `Variancia_indicadores`, `Ratio_IDA_IEG`

### 3. Treinamento com Regulariza√ß√£o

O XGBoost √© treinado com **regulariza√ß√£o** para evitar overfitting (sem regulariza√ß√£o, o treino atingia 100%):

| Par√¢metro | Valor | Efeito |
|-----------|-------|--------|
| `max_depth` | 4 | Limita profundidade das √°rvores (padr√£o: 6) |
| `min_child_weight` | 5 | M√≠nimo de amostras por folha |
| `subsample` | 0.8 | Amostragem de 80% dos dados por √°rvore |
| `colsample_bytree` | 0.8 | Amostragem de 80% das features por √°rvore |
| `reg_alpha` | 0.1 | Regulariza√ß√£o L1 (sparsity) |
| `reg_lambda` | 1.0 | Regulariza√ß√£o L2 (weight decay) |
| `learning_rate` | 0.1 | Taxa de aprendizado conservadora |
| `n_estimators` | 200 | Mais √°rvores compensam o learning_rate menor |

Essa configura√ß√£o reduziu o score de treino de **1.000 para ~0.99** e manteve o score de valida√ß√£o est√°vel, eliminando o overfitting.

### 4. Valida√ß√£o

- **Cross-Validation Independente (5-Fold)**: avalia generaliza√ß√£o do modelo no dataset completo, reportando m√©dia ¬± desvio padr√£o por m√©trica
- **Learning Curves**: gr√°fico de treino vs valida√ß√£o em fun√ß√£o do tamanho do dataset para diagn√≥stico visual de overfitting/underfitting
- M√©trica prim√°ria: **F1-Score** (equil√≠brio entre precis√£o e recall)
- Prioriza√ß√£o do **Recall** (evitar falsos negativos ‚Äî n√£o perder alunos em risco)

### 5. Top Features

| # | Feature | Import√¢ncia |
|---|---------|------------|
| 1 | N¬∫ Avalia√ß√µes | 11.13% |
| 2 | Idade 22 | 7.54% |
| 3 | Fase (encoded) | 7.51% |
| 4 | Indicado (flag) | 7.07% |
| 5 | Cf | 6.73% |

> A import√¢ncia est√° bem distribu√≠da entre as features (max. 11%), indicando que o modelo n√£o depende de uma √∫nica vari√°vel.

---

## üß™ Testes

```bash
# Executar todos os testes
pytest tests/ -v

# Com cobertura
pytest tests/ --cov=app --cov-report=term-missing

# Verificar cobertura m√≠nima de 80%
pytest tests/ --cov=app --cov-fail-under=80
```

**Resultado atual**: 105 testes passando.

---

## üìä Monitoramento

A API inclui monitoramento cont√≠nuo de **data drift**:

- **PSI (Population Stability Index)**: detecta mudan√ßas na distribui√ß√£o das features
- **KS-test**: teste estat√≠stico contra distribui√ß√£o de refer√™ncia
- **Logs de predi√ß√£o**: todas as predi√ß√µes s√£o registradas para an√°lise

Endpoints:
- `GET /monitoring/drift` ‚Äî Status de drift por feature
- `GET /monitoring/stats` ‚Äî Estat√≠sticas das predi√ß√µes

---

## üìÑ Licen√ßa

Projeto desenvolvido para o Datathon P√ìS TECH ‚Äî Machine Learning Engineering.

